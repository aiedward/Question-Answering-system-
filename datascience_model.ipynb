{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "# from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer \n",
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.multioutput import MultiOutputClassifier                  # included from scikit-learn version 0.18.1 and onwards\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'C:\\Users\\Pushpendra\\Desktop\\po\\datascience_datasets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_set = pd.read_csv(path,header=None,names=['tag','title'],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['r', 'regression', 'categorical-data']</td>\n",
       "      <td>Dummy coding a column in R with multiple levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['r', 'sequential-pattern-mining', 'traminer']</td>\n",
       "      <td>Sequence pattern mining on continuous dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['machine-learning', 'classification', 'evalua...</td>\n",
       "      <td>How to improve an existing (trained) classifier?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['machine-learning', 'data-mining', 'apache-sp...</td>\n",
       "      <td>Machine Learning model to find items that are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['xgboost']</td>\n",
       "      <td>Extracting information from DMatrix in xgboost...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag  \\\n",
       "0            ['r', 'regression', 'categorical-data']   \n",
       "1     ['r', 'sequential-pattern-mining', 'traminer']   \n",
       "2  ['machine-learning', 'classification', 'evalua...   \n",
       "3  ['machine-learning', 'data-mining', 'apache-sp...   \n",
       "4                                        ['xgboost']   \n",
       "\n",
       "                                               title  \n",
       "0    Dummy coding a column in R with multiple levels  \n",
       "1      Sequence pattern mining on continuous dataset  \n",
       "2   How to improve an existing (trained) classifier?  \n",
       "3  Machine Learning model to find items that are ...  \n",
       "4  Extracting information from DMatrix in xgboost...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_labels = []                                                                  # contains values of d_set['tag']\n",
    "for i in d_set['tag']:  \n",
    "    y_labels.append(ast.literal_eval(i))                                       # to remove unicodeed string \n",
    "y_labels = [j for i in y_labels for j in i] \n",
    "y_labels = list(set(y_labels))\n",
    "\n",
    "# for i in range(len(y_labels)):\n",
    "#     if (y_labels[i].find('-') > -1):\n",
    "#         y_labels[i] = y_labels[i].replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class lemmatokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "        self.token_pattern = r\"(?u)\\b\\w\\w+\\b\"       \n",
    "#         self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self,doc):                                                     # here, doc is one string sentence\n",
    "        token_pattern = re.compile(self.token_pattern)\n",
    "        return [self.stemmer.stem(t) for t in token_pattern.findall(doc)]       # return lambda doc: token_pattern.findall(doc) \n",
    "#         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect_title = CountVectorizer(max_df=0.5,min_df=5,stop_words='english',tokenizer=lemmatokenizer(),ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect_title = TfidfVectorizer(smooth_idf=False,max_df=0.5,min_df=5,stop_words='english',tokenizer=lemmatokenizer(),ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To make it clear what actually we are doing...\n",
    "\n",
    "### tag                           \n",
    "['r', 'machine-learning', 'ai'] \n",
    "   \n",
    "### Labelencoder() \n",
    "[32, 324, 17]              \n",
    "   \n",
    "### MultiLabelBinarizer()\n",
    "[0,0,0,0,........1,0,0,1,1,0,...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['r', 'regression', 'categorical-data']</td>\n",
       "      <td>Dummy coding a column in R with multiple levels</td>\n",
       "      <td>[208, 216, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['r', 'sequential-pattern-mining', 'traminer']</td>\n",
       "      <td>Sequence pattern mining on continuous dataset</td>\n",
       "      <td>[208, 236, 267]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['machine-learning', 'classification', 'evalua...</td>\n",
       "      <td>How to improve an existing (trained) classifier?</td>\n",
       "      <td>[150, 36, 83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['machine-learning', 'data-mining', 'apache-sp...</td>\n",
       "      <td>Machine Learning model to find items that are ...</td>\n",
       "      <td>[150, 59, 13, 113]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['xgboost']</td>\n",
       "      <td>Extracting information from DMatrix in xgboost...</td>\n",
       "      <td>[281]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag  \\\n",
       "0            ['r', 'regression', 'categorical-data']   \n",
       "1     ['r', 'sequential-pattern-mining', 'traminer']   \n",
       "2  ['machine-learning', 'classification', 'evalua...   \n",
       "3  ['machine-learning', 'data-mining', 'apache-sp...   \n",
       "4                                        ['xgboost']   \n",
       "\n",
       "                                               title           label_num  \n",
       "0    Dummy coding a column in R with multiple levels      [208, 216, 34]  \n",
       "1      Sequence pattern mining on continuous dataset     [208, 236, 267]  \n",
       "2   How to improve an existing (trained) classifier?       [150, 36, 83]  \n",
       "3  Machine Learning model to find items that are ...  [150, 59, 13, 113]  \n",
       "4  Extracting information from DMatrix in xgboost...               [281]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()  \n",
    "le.fit(y_labels) \n",
    "d_set['label_num'] = pd.Series([le.transform(ast.literal_eval(i)) for i in d_set['tag']])\n",
    "d_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_y_labels = d_set['label_num'].values.tolist()\n",
    "\n",
    "# print (new_y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer() \n",
    "mlb.fit(new_y_labels)\n",
    "\n",
    "# mlb.transform(new_y_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 282)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tag_dtm = mlb.transform(new_y_labels) \n",
    "\n",
    "# print (type(y_tag_dtm))\n",
    "# y_tag_dtm = pd.Series(y_tag_dtm) \n",
    "\n",
    "y_tag_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_labels = d_set['title'].values.tolist()\n",
    "\n",
    "# print (X_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3548x922 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 18043 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_title.fit(X_labels)\n",
    "X_title_dtm = vect_title.transform(X_labels)\n",
    "\n",
    "# vect_title.get_feature_names()\n",
    "# vect_title.get_params\n",
    "# print (X_title_dtm.toarray())\n",
    "\n",
    "X_title_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation\n",
    "## implementation PCA :\n",
    "I don't know why but for some reason it's not doing its job for MultiLabel output...it's throwing error \n",
    "during the training of classifier (both knn_clf and rf_clf) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0 -0.1665 -0.1138 -0.1273 -0.1345 -0.1034  0.0072 -0.0181  0.0605 -0.0463   \n",
      "1 -0.1684 -0.1009 -0.1551 -0.1138 -0.1179  0.0110 -0.1246  0.0034 -0.0352   \n",
      "2 -0.1543 -0.1186 -0.1223 -0.0421 -0.0548 -0.0232  0.0761 -0.2428  0.4300   \n",
      "3 -0.4502  1.6132  0.3952  0.8012  0.7419 -0.3519 -0.3020 -0.0869 -0.3281   \n",
      "4 -0.2185 -0.1189 -0.1356 -0.0682 -0.1036 -0.0390 -0.0825  0.0239 -0.0624   \n",
      "\n",
      "       9    ...        90      91      92      93      94      95      96  \\\n",
      "0 -0.0123   ...    0.0582  0.0038  0.0260 -0.2615 -0.0631  0.3202 -0.0066   \n",
      "1 -0.0273   ...    0.0153  0.1127 -0.2583 -0.1806  0.0200 -0.1053  0.0678   \n",
      "2 -0.3340   ...    0.0054  0.0076  0.0501  0.0410  0.0152 -0.0531  0.0049   \n",
      "3 -0.2772   ...    0.0831 -0.1005  0.1559  0.1070  0.2640  0.0794  0.2680   \n",
      "4 -0.0411   ...    0.1493 -0.0826  0.1375  0.3090 -0.0828  0.0074  0.1183   \n",
      "\n",
      "       97      98      99  \n",
      "0  0.4048  0.0513 -0.0091  \n",
      "1  0.0162  0.1068  0.1224  \n",
      "2 -0.0950 -0.0474  0.0216  \n",
      "3 -0.0890  0.0895 -0.0964  \n",
      "4 -0.1323  0.1028  0.2388  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100).fit(X_title_dtm.toarray())\n",
    "pca_samples = pca.transform(X_title_dtm.toarray())\n",
    "\n",
    "pca_df = pd.DataFrame(np.round(pca_samples,4))\n",
    "\n",
    "print (pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 922)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(X_title_dtm.toarray(),columns=vect_title.get_feature_names())\n",
    "\n",
    "# new_df.head()\n",
    "# new_df.ix[1].to_dict().values()\n",
    "\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = collections.Counter(vect_title.get_feature_names())\n",
    "# print (d['ai']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['target_list'] = [i for i in y_tag_dtm] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_df.columns[:100]  \n",
    "# new_df.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3548x922 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 18043 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_title.fit(X_labels)\n",
    "X_title_dtm_tfidf = tfidf_vect_title.transform(X_labels)\n",
    "\n",
    "X_title_dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df_of_tfidf = pd.DataFrame(X_title_dtm_tfidf.toarray(),columns=tfidf_vect_title.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df_of_tfidf['target_list'] = [i for i in y_tag_dtm] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = new_df_of_tfidf['target_list'] \n",
    "X = new_df_of_tfidf.drop('target_list',axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = new_df['target_list']\n",
    "# X = new_df.drop('target_list',axis=1)\n",
    "\n",
    "# # X = X.ix[:]                                           # it will return each feature row wise to X\n",
    "# # X = X.values\n",
    "\n",
    "# print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(X.values.tolist())                           # it will convert list to numpy ndarray\n",
    "y = np.array(y.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (X[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_X = PCA(n_components=200).fit_transform(X)  \n",
    "pca_X = np.round(pca_X,4)\n",
    "\n",
    "pca_y = PCA(n_components=50).fit_transform(y)  \n",
    "pca_y = np.round(pca_y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.392  -0.3133  0.7996 ..., -0.056   0.1193  0.0281]\n",
      " [-0.3741 -0.3108  0.7694 ..., -0.0126  0.0037 -0.0357]\n",
      " [ 0.8004 -0.1387 -0.1726 ..., -0.0014  0.0079  0.0908]\n",
      " ..., \n",
      " [-0.2878 -0.1038 -0.0992 ..., -0.0085 -0.0222  0.0042]\n",
      " [-0.2894 -0.0968 -0.1342 ..., -0.012  -0.0047 -0.0144]\n",
      " [-0.3434 -0.0898 -0.1336 ..., -0.0271  0.0426 -0.1531]]\n"
     ]
    }
   ],
   "source": [
    "print (pca_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(pca_X, pca_y, test_size=0.2, random_state=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = Pipeline([('classifier',OneVsRestClassifier(SVC(probability=True,random_state=0)))])  # just to for Pipeline example\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "# mnb_clf = MultinomialNB()                                                                   # not working for MultiLabelinput\n",
    "\n",
    "# time_pass_y = np.random.randint(2,size=(2838,1))                                            # produce ndarray of size 2838 X 1\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "# mnb_clf.fit(X_train, y_train) \n",
    "\n",
    "knn_pred = knn_clf.predict(X_test)  \n",
    "# mnb_pred = mnb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_clf = OneVsRestClassifier(SVC(probability=True,random_state=0))\n",
    "svc_clf.fit(X_train, y_train)\n",
    "svc_pred = svc_clf.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033802816901408447"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "knn_report = metrics.classification_report(y_test[:], knn_pred[:]) \n",
    "knn_f1_score = metrics.f1_score(y_test[:], knn_pred[:], average='samples') \n",
    "knn_precision_recall_fscore = metrics.precision_recall_fscore_support(y_test, knn_pred, average='samples')  # on full data-set\n",
    "knn_avg_precision_score = metrics.average_precision_score(y_test, knn_pred, average='samples')\n",
    "knn_roc_auc_score = metrics.roc_auc_score(y_test, knn_pred, average='samples')\n",
    "\n",
    "# mnb_report = metrics.classification_report(y_test[:100], mnb_pred[:100])  #throwing error mnb_clf can't work on multilabel O/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_report = metrics.classification_report(y_test[:], svc_pred[:]) \n",
    "svc_f1_score = metrics.f1_score(y_test[:], svc_pred[:], average='samples') \n",
    "svc_precision_recall_fscore = metrics.precision_recall_fscore_support(y_test, svc_pred, average='samples')  # on full data-set\n",
    "svc_avg_precision_score = metrics.average_precision_score(y_test, svc_pred, average='samples')\n",
    "svc_roc_auc_score = metrics.roc_auc_score(y_test, svc_pred, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true=y_test[:], y_pred=svc_pred[:])          # I think it's same as calculating hamming_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For svc_clf (LinearSVC) : \n",
      "precision, recall, fbeta_score, support :  (0.0, 0.0, 0.0, None)\n",
      "f1_score :  0.0\n",
      "avg. precision_score :  0.504609929078\n",
      "roc_auc_score :  0.5\n"
     ]
    }
   ],
   "source": [
    "print \"For svc_clf (LinearSVC) : \"\n",
    "print \"precision, recall, fbeta_score, support : \",svc_precision_recall_fscore\n",
    "print \"f1_score : \",svc_f1_score\n",
    "print \"avg. precision_score : \",svc_avg_precision_score \n",
    "print \"roc_auc_score : \",svc_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033802816901408447"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true=y_test[:], y_pred=knn_pred[:])          # I think it's same as calculating hamming_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For knn_clf (KNearestNeighbours) : \n",
      "precision, recall, fbeta_score, support :  (0.28286384976525825, 0.13798122065727697, 0.17197406662195394, None)\n",
      "f1_score :  0.171974066622\n",
      "avg. precision_score :  0.401754569973\n",
      "roc_auc_score :  0.568224767594\n"
     ]
    }
   ],
   "source": [
    "# print (knn_report)                                   # its type is str\n",
    "\n",
    "print \"For knn_clf (KNearestNeighbours) : \"\n",
    "print \"precision, recall, fbeta_score, support : \",knn_precision_recall_fscore\n",
    "print \"f1_score : \",knn_f1_score\n",
    "print \"avg. precision_score : \",knn_avg_precision_score \n",
    "print \"roc_auc_score : \",knn_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def does_test_tag_match(d, list_of_tags):      # no need for this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine-learning']]\n"
     ]
    }
   ],
   "source": [
    "test = [\"how to use policy iteration in ml ?\"]\n",
    "# test = [\"what is lstm ?\"] \n",
    "\n",
    "# test_dtm = vect_title.transform(test)                                           # without tfidf\n",
    "test_dtm = tfidf_vect_title.transform(test)                                       # with tfidf\n",
    "\n",
    "# print (test_dtm.toarray()[0])\n",
    "status = False\n",
    "for i in test_dtm.toarray()[0]:\n",
    "    if (i!=0):\n",
    "        status = True\n",
    "        break\n",
    "\n",
    "ans = knn_clf.predict(test_dtm.toarray())\n",
    "ans = mlb.inverse_transform(ans)\n",
    "\n",
    "if (len(ans[0])==0 or status==False):\n",
    "    print (\"sorry, we can't predict your category!!!\")\n",
    "else:\n",
    "    ans = le.inverse_transform(ans)\n",
    "    print (ans)\n",
    "    \n",
    "    \n",
    "# mlb.transform([[224,0,100]]) \n",
    "# ans \n",
    "# test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "rf_clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059999999999999998"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true=y_test[:100], y_pred=rf_pred[:100])          # I think it's same as calculating hamming_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040845070422535212"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rf_clf.predict_log_proba(X_test)                                               # no such function in MultiOutputClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (knn_clf.predict_proba(X_train))                                         # running smooth\n",
    "\n",
    "# print (rf_clf.predict_proba(X_train[:5]))                                      # showing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_report = metrics.classification_report(y_test[:], rf_pred[:])\n",
    "rf_f1_score = metrics.f1_score(y_test, rf_pred, average='samples')  \n",
    "rf_precision_recall_fscore = metrics.precision_recall_fscore_support(y_test, rf_pred, average='samples')  # on full data-set\n",
    "rf_avg_precision_score = metrics.average_precision_score(y_test, rf_pred, average='samples')\n",
    "rf_roc_auc_score = metrics.roc_auc_score(y_test, rf_pred, average='samples') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rf_clf (RandomForest) : \n",
      "precision, recall, fbeta_score, support :  (0.332018779342723, 0.1898826291079812, 0.22276995305164318, None)\n",
      "f1_score :  0.222769953052\n",
      "avg. precision_score :  0.468282639097\n",
      "roc_auc_score :  0.594238774341\n"
     ]
    }
   ],
   "source": [
    "# print (rf_report) \n",
    "\n",
    "print \"For rf_clf (RandomForest) : \"\n",
    "print \"precision, recall, fbeta_score, support : \",rf_precision_recall_fscore\n",
    "print \"f1_score : \",rf_f1_score  \n",
    "print \"avg. precision_score : \",rf_avg_precision_score \n",
    "print \"roc_auc_score : \",rf_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['neuralnetwork' 'visualization']]\n"
     ]
    }
   ],
   "source": [
    "# test = [\"what is reinforcement learning ?\"] \n",
    "test = [\"what is ai,lstm and data visualization ?\"] \n",
    "\n",
    "# test_dtm = vect_title.transform(test)                                            # without tfidf\n",
    "test_dtm = tfidf_vect_title.transform(test)                                        # with tfidf\n",
    "\n",
    "status = False\n",
    "for i in test_dtm.toarray()[0]:\n",
    "    if (i!=0):\n",
    "        status = True\n",
    "        break\n",
    "\n",
    "ans = rf_clf.predict(test_dtm.toarray())\n",
    "ans = mlb.inverse_transform(ans)\n",
    "if (len(ans[0])==0 or status==False):\n",
    "    print (\"sorry, we can't predict your category!!!\")\n",
    "else:\n",
    "    ans = le.inverse_transform(ans)\n",
    "    print (ans)\n",
    "    \n",
    "# mlb.transform([[224,0,100]]) \n",
    "# ans \n",
    "# test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datascience_classifier.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf_clf, 'datascience_classifier.pkl')\n",
    "# new_clf = joblib.load('classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pkl_clf = joblib.load('datascience_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pkl_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"sorry, we can't predict your category!!!\"]]\n"
     ]
    }
   ],
   "source": [
    "test = [\"How to use policy iteration in ml ?\"] \n",
    "\n",
    "# test_dtm = vect_title.transform(test)                                           # without tfidf\n",
    "test_dtm = tfidf_vect_title.transform(test)                                       # with tfidf       \n",
    "\n",
    "status = False\n",
    "for i in test_dtm.toarray()[0]:\n",
    "    if (i!=0):\n",
    "        status = True\n",
    "        break\n",
    "        \n",
    "ans = new_pkl_clf.predict(test_dtm.toarray())\n",
    "ans = mlb.inverse_transform(ans)\n",
    "if (len(ans[0])==0 or status==False):\n",
    "    print ([[\"sorry, we can't predict your category!!!\"]]) \n",
    "else:\n",
    "    ans = le.inverse_transform(ans)\n",
    "    print (ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
